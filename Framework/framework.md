# ü§ñ Python AI & Data Science Foundation

Welcome to my foundational repository for Artificial Intelligence and Data Science! 
As an Information Technology student at Politeknik Negeri Madiun, I created this repository to document my journey in mastering the core Python libraries used in the AI industry.

This project serves as a practical cheat sheet and codebase for data manipulation, machine learning, and deep learning concepts.

## üóÇÔ∏è Repository Modules

This repository is divided into four main foundational modules:

### 1. Numerical Operations with NumPy (`numpy.py`)
This script demonstrates the absolute basics of handling numerical data efficiently.
1. * **Array Creation**   : Creating arrays directly from standard Python lists.
2. * **Broadcasting**     : Applying mathematical operations directly to all elements in an array without using loops.
3. * **Basic Statistics** : Calculating essential metrics like the mean, maximum, minimum, and total sum.
4. * **Reshaping**        : Altering the dimensions of data, such as converting a flat array of numbers into a 2x5 matrix.

### 2. Data Manipulation with Pandas (`pandas.py`)
This module focuses on structured data manipulation, functioning much like a programmatic spreadsheet. * **DataFrame Initialization**               : Creating structured tables (DataFrames) from standard Python dictionaries.
1. * **Data Aggregation**      : Calculating summary statistics, such as finding the average value in an 'Age' column.
2. * **Filtering**             : Extracting specific rows of data that meet certain conditions (e.g., employees older than 25).
3. * **Vectorized Operations** : Creating new columns mathematically, such as calculating a 10% bonus based on the 'Salary' column.

### 3. Machine Learning with Scikit-Learn (`scikit.py`)
This script implements a complete, fundamental Machine Learning pipeline. * **Dataset Handling**: Loading the classic Iris dataset provided by scikit-learn for classification tasks.
1. * **Data Splitting**          : Dividing the data into training and testing sets to evaluate how well the model generalizes to new data.
2. * **Model Selection**         : Initializing an ensemble method, specifically the Random Forest Classifier.
3. * **Training and Evaluation** : Fitting the model to the training data, making predictions on the test set, and calculating the model's performance using an accuracy score.